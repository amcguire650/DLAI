{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":82250,"databundleVersionId":8966764,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-31T23:36:37.887576Z","iopub.execute_input":"2025-08-31T23:36:37.888046Z","iopub.status.idle":"2025-08-31T23:36:37.896793Z","shell.execute_reply.started":"2025-08-31T23:36:37.888015Z","shell.execute_reply":"2025-08-31T23:36:37.895685Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/train-a-strong-stockfish-wdl-model/sample_submission.csv\n/kaggle/input/train-a-strong-stockfish-wdl-model/shuffled_fens.csv\n/kaggle/input/train-a-strong-stockfish-wdl-model/test.csv\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/train-a-strong-stockfish-wdl-model/shuffled_fens.csv')\ndf.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T23:36:50.596386Z","iopub.execute_input":"2025-08-31T23:36:50.596763Z","iopub.status.idle":"2025-08-31T23:37:04.518193Z","shell.execute_reply.started":"2025-08-31T23:36:50.596739Z","shell.execute_reply":"2025-08-31T23:37:04.516974Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['FEN', 'WDL'], dtype='object')"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df.sample(10)\ndf.head()\ndf['WDL'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T23:37:07.140083Z","iopub.execute_input":"2025-08-31T23:37:07.140604Z","iopub.status.idle":"2025-08-31T23:37:07.663010Z","shell.execute_reply.started":"2025-08-31T23:37:07.140568Z","shell.execute_reply":"2025-08-31T23:37:07.662067Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([1. , 0. , 0.5])"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"!pip install python-chess","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T23:37:15.071880Z","iopub.execute_input":"2025-08-31T23:37:15.072218Z","iopub.status.idle":"2025-08-31T23:37:28.098212Z","shell.execute_reply.started":"2025-08-31T23:37:15.072186Z","shell.execute_reply":"2025-08-31T23:37:28.096950Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting python-chess\n  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\nCollecting chess<2,>=1 (from python-chess)\n  Downloading chess-1.11.2.tar.gz (6.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nDownloading python_chess-1.999-py3-none-any.whl (1.4 kB)\nBuilding wheels for collected packages: chess\n  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=2ce45482dbbac44b5079c9a18a4c444a54a6324637a93f25089fedba76d785e5\n  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\nSuccessfully built chess\nInstalling collected packages: chess, python-chess\nSuccessfully installed chess-1.11.2 python-chess-1.999\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nimport chess\nimport chess.engine\nimport chess.pgn\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom joblib import Parallel, delayed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T23:37:38.435467Z","iopub.execute_input":"2025-08-31T23:37:38.435804Z","iopub.status.idle":"2025-08-31T23:37:38.442891Z","shell.execute_reply.started":"2025-08-31T23:37:38.435781Z","shell.execute_reply":"2025-08-31T23:37:38.441918Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(chess.Board('1r6/R3Pk2/6p1/2KB3p/5P2/8/8/8 b - - 5 50'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T23:37:44.365736Z","iopub.execute_input":"2025-08-31T23:37:44.366570Z","iopub.status.idle":"2025-08-31T23:37:44.392292Z","shell.execute_reply.started":"2025-08-31T23:37:44.366541Z","shell.execute_reply":"2025-08-31T23:37:44.390179Z"}},"outputs":[{"name":"stdout","text":". r . . . . . .\nR . . . P k . .\n. . . . . . p .\n. . K B . . . p\n. . . . . P . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def parse_fen(fen):\n    board = chess.Board(fen)  # Extract the full FEN\n    rows = board.board_fen().split(\"/\")                               \n    features = {\n        'FEN' : board.board_fen(),\n        'num_white_pawns': len(board.pieces(chess.PAWN, chess.WHITE)),\n        'num_black_pawns': len(board.pieces(chess.PAWN, chess.BLACK)),\n        'num_white_knights': len(board.pieces(chess.KNIGHT, chess.WHITE)),\n        'num_black_knights': len(board.pieces(chess.KNIGHT, chess.BLACK)),\n        'num_white_bishops': len(board.pieces(chess.BISHOP, chess.WHITE)),\n        'num_black_bishops': len(board.pieces(chess.BISHOP, chess.BLACK)),\n        'num_white_rooks': len(board.pieces(chess.ROOK, chess.WHITE)),\n        'num_black_rooks': len(board.pieces(chess.ROOK, chess.BLACK)),\n        'num_white_queens': len(board.pieces(chess.QUEEN, chess.WHITE)),\n        'num_black_queens': len(board.pieces(chess.QUEEN, chess.BLACK)),\n        #Castling options\n        'can_white_cstl_ks' : int(board.has_kingside_castling_rights(chess.WHITE)),\n        'can_white_cstl_qs' : int(board.has_queenside_castling_rights(chess.WHITE)),\n        'can_black_cstl_ks' : int(board.has_kingside_castling_rights(chess.BLACK)),\n        'can_black_cstl_qs' : int(board.has_queenside_castling_rights(chess.BLACK)),\n        # Total pieces for each color\n        'num_white_pieces': sum(len(board.pieces(piece_type, chess.WHITE)) for piece_type in chess.PIECE_TYPES),\n        'num_black_pieces': sum(len(board.pieces(piece_type, chess.BLACK)) for piece_type in chess.PIECE_TYPES),\n        # Board status. Each digit represents a status issue. 0 means no issues\n        'status' : board.status(),\n        # Number of BW turns\n        'round' : board.fullmove_number,\n        # Next turn. 1-white, 0-black\n        'is_white_to_move': int(board.turn),\n        \"row1\" : rows[0],\n        \"row2\" : rows[1],\n        \"row3\" : rows[2],\n        \"row4\" : rows[3],\n        \"row5\" : rows[4],\n        \"row6\" : rows[5],\n        \"row7\" : rows[6],\n        \"row8\" : rows[7],\n        \n    }\n    return features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T23:37:50.368733Z","iopub.execute_input":"2025-08-31T23:37:50.369198Z","iopub.status.idle":"2025-08-31T23:37:50.385078Z","shell.execute_reply.started":"2025-08-31T23:37:50.369163Z","shell.execute_reply":"2025-08-31T23:37:50.383722Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Parallelize FEN parsing\ndef parse_fen_parallel(fen_list, n_jobs=-1):\n    return Parallel(n_jobs=n_jobs)(delayed(parse_fen)(fen) for fen in fen_list)\n\n# Apply parallel parsing\n# Subset shuffle file\n# fen_list = df[0:1000000]['FEN'].tolist()\nfen_list = df[0:100000]['FEN']\nfen_features = parse_fen_parallel(fen_list)\nfeatures_df = pd.DataFrame(fen_features)\n\nfeatures_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:35.084848Z","iopub.execute_input":"2025-08-31T21:17:35.085263Z","iopub.status.idle":"2025-08-31T21:17:47.196801Z","shell.execute_reply.started":"2025-08-31T21:17:35.085225Z","shell.execute_reply":"2025-08-31T21:17:47.195607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#better to not select by index in case df changes.  Fix if time.\nX = features_df.iloc[:, 1:19]\n# y = df[0:100000]['WDL'].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:47.197939Z","iopub.execute_input":"2025-08-31T21:17:47.198301Z","iopub.status.idle":"2025-08-31T21:17:47.20673Z","shell.execute_reply.started":"2025-08-31T21:17:47.19827Z","shell.execute_reply":"2025-08-31T21:17:47.205201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# map WDL values to categories\ny = pd.DataFrame(df[0:100000]['WDL'])\n\ntarget_encoding = {1:1, 0:0, .5:2}\ny['target'] = y['WDL'].map(target_encoding)\n\ny = pd.DataFrame(y['target'])\n\nprint(y.sample(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:47.208363Z","iopub.execute_input":"2025-08-31T21:17:47.208849Z","iopub.status.idle":"2025-08-31T21:17:47.286061Z","shell.execute_reply.started":"2025-08-31T21:17:47.208819Z","shell.execute_reply":"2025-08-31T21:17:47.284955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\n\nask_llm = pipeline(\n    model = \"Qwen/Qwen2.5-3B-Instruct\"\n)\n\nprint(ask_llm(\"1r6/R3Pk2/6p1/2KB3p/5P2/8/8/8\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T23:10:50.873668Z","iopub.execute_input":"2025-08-31T23:10:50.875020Z","iopub.status.idle":"2025-08-31T23:13:52.918236Z","shell.execute_reply.started":"2025-08-31T23:10:50.874946Z","shell.execute_reply":"2025-08-31T23:13:52.916841Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bb5349cfa5f484bb66b9f4e44c3c64a"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"[{'generated_text': \"1r6/R3Pk2/6p1/2KB3p/5P2/8/8/8 w - - 0 1',\\n    'e2e4 e7e5 g1f3 c7c5 e2e4 e7e5 g1f3 c7c5 d2d4 b8c6 d7d5 f2f4 d7d5 f2f4 c6b7 b8c6 d7d5 f2f4 c6b7 c5a6 b7c6 d7d5 f2f4 c6b7 b8c6 d7d5 f2f4 c6b7 b8c6 d7d5 f2f4 c6b7 b8c6 d7d5 f2f4 c6b7 b8c6 d7d5 f2f4 c6b7 b8c6 d7d5 f2f4 c6b7 b8c6 d7d5 f2f4 c6b7 b8c6 d7d5 f2f4 c6b7 b8c6 d7d5 f2f4 c6b7 b8c6 d7d5 f2f4 c6b7 b8c6 d7\"}]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\ntarget_encoding = {1:'White wins', 0:'Black Wins', .5:'Draw'}\n\nlabel_df = pd.DataFrame(df[0:100000]['WDL'])\n\nlabel_df['target'] = label_df['WDL'].map(target_encoding)\n\nsplit_df = pd.DataFrame(df[0:100000]['FEN'])\nsplit_df['positions'] = split_df['FEN'].str.split(' ', expand=True)[0]\n# sample_df = pd.concat([split_df['positions'], label_df], axis=1)\nsample_df['sample'] = split_df['positions'] + \"/n\" + label_df['target']\nsample_df = pd.DataFrame(sample_df['sample'])\n\nsample_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T00:27:16.493195Z","iopub.execute_input":"2025-09-01T00:27:16.493615Z","iopub.status.idle":"2025-09-01T00:27:16.738375Z","shell.execute_reply.started":"2025-09-01T00:27:16.493586Z","shell.execute_reply":"2025-09-01T00:27:16.737283Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"                                              sample\n0  r1b4r/1p3kb1/p2pp1p1/3q3p/3N1Pp1/2P3R1/PP1Q1BP...\n1  r1bqkb1r/pp3ppp/2np1n2/8/2BNP3/8/PP3PPP/RNBQK2...\n2             8/R7/5k2/2pqp3/6n1/8/8/1K6/nBlack Wins\n3          1r6/R3Pk2/6p1/2KB3p/5P2/8/8/8/nWhite wins\n4  2RB2bk/p2n3p/4Np2/8/2B3P1/1P3p1P/1P3P1K/2br4/n...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>r1b4r/1p3kb1/p2pp1p1/3q3p/3N1Pp1/2P3R1/PP1Q1BP...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>r1bqkb1r/pp3ppp/2np1n2/8/2BNP3/8/PP3PPP/RNBQK2...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8/R7/5k2/2pqp3/6n1/8/8/1K6/nBlack Wins</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1r6/R3Pk2/6p1/2KB3p/5P2/8/8/8/nWhite wins</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2RB2bk/p2n3p/4Np2/8/2B3P1/1P3p1P/1P3P1K/2br4/n...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ndef preprocess(sample):\n    tokenizer = AutoTokenizer.from_pretrained(\n        \"Qwen/Qwen2.5-3B-Instruct\"\n    )\n    \n    sample = \"1r6/R3Pk2/6p1/2KB3p/5P2/8/8/8\t\" + \"\\n\" + \"2\"\n    \n    tokenized = tokenizer(sample,\n             max_length=50,\n             truncation=True,\n              padding=\"max_length\"\n            )\n    \n    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n    \n    return tokenized \n\nsample_list = sample_df['sample']\n\ndef map_tokens_parallel(sample_list, n_jobs=-1):\n    return Parallel(n_jobs=n_jobs)(delayed(preprocess)(sample) for sample in sample_list)\n\ndata = sample_list.map(preprocess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T00:52:30.366219Z","iopub.execute_input":"2025-09-01T00:52:30.366626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Want to try preprocess in parallel\n# sample_list = sample_df['sample']\n\n# def map_tokens_parallel(sample_list, n_jobs=-1):\n#     return Parallel(n_jobs=n_jobs)(delayed(preprocess)(sample_list) for sample in sample_list)\n\n# data = map_tokens_parallel(sample_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T00:48:28.191094Z","iopub.execute_input":"2025-09-01T00:48:28.191536Z","iopub.status.idle":"2025-09-01T00:48:28.277001Z","shell.execute_reply.started":"2025-09-01T00:48:28.191503Z","shell.execute_reply":"2025-09-01T00:48:28.275363Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3923581509.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_tokens_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/3923581509.py\u001b[0m in \u001b[0;36mmap_tokens_parallel\u001b[0;34m(sample_list, n_jobs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmap_tokens_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_tokens_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1782\u001b[0m             \u001b[0;31m# worker traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;31m# called directly or if the generator is gc'ed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             \u001b[0merror_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_warn_exit_early\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# callback thread, and is stored internally. It's just waiting to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;31m# For other backends, the main thread needs to run the retrieval step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m                     \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1494\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m                     \u001b[0;31m# Handle the fact that the generator of task raised an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3923581509.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmap_tokens_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_tokens_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'preprocess' is not defined"],"ename":"NameError","evalue":"name 'preprocess' is not defined","output_type":"error"}],"execution_count":55},{"cell_type":"code","source":"print(data[\"train\"][9])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"       from peft import LoraConfig, get_peft_model, TaskType\n       from transformers import AutoModelForCausalLM\n       Import torch\n\n       model = AutoModelForCausalLM.from_pretrained(\n           \"Qwen/Qwen2.5-3B-Instruct\",\n           torch_dtype=torch.float16\n       )\n\n       lora_config = LoraConfig(\n           task_type=TaskType.CAUSAL_LM,\n           target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"]\n       )\n\n       model = get_peft_model(model, lora_config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntrain_args = TrainingArguments(\n    num_train_epochs = 2,\n    learning_rate = 0.001,\n    logging_steps = 25,\n    fp16 = True\n)\n\ntrainer = Trainer(\n    args=train_args,\n    model=model,\n    train_dataset=data[\"train\"]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.save_mode(\"/kaggle/working/\")\ntokenizer.save_pretrained(\"/kaggle/working/\")\n# trainer.save_mode(\"/kaggle/temp/\")\n# tokenizer.save_pretrained(\"/kaggle/temp/\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ask_trained_llm = pipeline(\n    model = \"/kaggle/working/\",\n    tokenizer = \"/kaggle/working/\"\n)\n\nprint(ask_trained_llm(\"\")[0][\"generated_text\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}