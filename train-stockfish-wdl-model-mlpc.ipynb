{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":82250,"databundleVersionId":8966764,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:05.788028Z","iopub.execute_input":"2025-08-31T21:17:05.788351Z","iopub.status.idle":"2025-08-31T21:17:08.622832Z","shell.execute_reply.started":"2025-08-31T21:17:05.788317Z","shell.execute_reply":"2025-08-31T21:17:08.621796Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/train-a-strong-stockfish-wdl-model/sample_submission.csv\n/kaggle/input/train-a-strong-stockfish-wdl-model/shuffled_fens.csv\n/kaggle/input/train-a-strong-stockfish-wdl-model/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/train-a-strong-stockfish-wdl-model/shuffled_fens.csv')\ndf.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:08.625058Z","iopub.execute_input":"2025-08-31T21:17:08.625519Z","iopub.status.idle":"2025-08-31T21:17:22.860345Z","shell.execute_reply.started":"2025-08-31T21:17:08.625494Z","shell.execute_reply":"2025-08-31T21:17:22.859404Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"Index(['FEN', 'WDL'], dtype='object')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df.sample(10)\ndf.head()\ndf['WDL'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:22.861276Z","iopub.execute_input":"2025-08-31T21:17:22.861614Z","iopub.status.idle":"2025-08-31T21:17:23.330879Z","shell.execute_reply.started":"2025-08-31T21:17:22.861591Z","shell.execute_reply":"2025-08-31T21:17:23.329390Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"array([1. , 0. , 0.5])"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"!pip install python-chess","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:23.332991Z","iopub.execute_input":"2025-08-31T21:17:23.333369Z","iopub.status.idle":"2025-08-31T21:17:33.452608Z","shell.execute_reply.started":"2025-08-31T21:17:23.333336Z","shell.execute_reply":"2025-08-31T21:17:33.450561Z"}},"outputs":[{"name":"stdout","text":"Collecting python-chess\n  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\nCollecting chess<2,>=1 (from python-chess)\n  Downloading chess-1.11.2.tar.gz (6.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nDownloading python_chess-1.999-py3-none-any.whl (1.4 kB)\nBuilding wheels for collected packages: chess\n  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=27535768f5477d578e2e403382c975d796974e716f049e4ee91adfd9e863a00a\n  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\nSuccessfully built chess\nInstalling collected packages: chess, python-chess\nSuccessfully installed chess-1.11.2 python-chess-1.999\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nimport chess\nimport chess.engine\nimport chess.pgn\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom joblib import Parallel, delayed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:33.455510Z","iopub.execute_input":"2025-08-31T21:17:33.455884Z","iopub.status.idle":"2025-08-31T21:17:34.966939Z","shell.execute_reply.started":"2025-08-31T21:17:33.455845Z","shell.execute_reply":"2025-08-31T21:17:34.965865Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(chess.Board('1r6/R3Pk2/6p1/2KB3p/5P2/8/8/8 b - - 5 50'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:34.968200Z","iopub.execute_input":"2025-08-31T21:17:34.968696Z","iopub.status.idle":"2025-08-31T21:17:34.974086Z","shell.execute_reply.started":"2025-08-31T21:17:34.968669Z","shell.execute_reply":"2025-08-31T21:17:34.972882Z"}},"outputs":[{"name":"stdout","text":". r . . . . . .\nR . . . P k . .\n. . . . . . p .\n. . K B . . . p\n. . . . . P . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def parse_fen(fen):\n    board = chess.Board(fen)  # Extract the full FEN\n    rows = board.board_fen().split(\"/\")                               \n    features = {\n        'FEN' : board.board_fen(),\n        'num_white_pawns': len(board.pieces(chess.PAWN, chess.WHITE)),\n        'num_black_pawns': len(board.pieces(chess.PAWN, chess.BLACK)),\n        'num_white_knights': len(board.pieces(chess.KNIGHT, chess.WHITE)),\n        'num_black_knights': len(board.pieces(chess.KNIGHT, chess.BLACK)),\n        'num_white_bishops': len(board.pieces(chess.BISHOP, chess.WHITE)),\n        'num_black_bishops': len(board.pieces(chess.BISHOP, chess.BLACK)),\n        'num_white_rooks': len(board.pieces(chess.ROOK, chess.WHITE)),\n        'num_black_rooks': len(board.pieces(chess.ROOK, chess.BLACK)),\n        'num_white_queens': len(board.pieces(chess.QUEEN, chess.WHITE)),\n        'num_black_queens': len(board.pieces(chess.QUEEN, chess.BLACK)),\n        #Castling options\n        'can_white_cstl_ks' : int(board.has_kingside_castling_rights(chess.WHITE)),\n        'can_white_cstl_qs' : int(board.has_queenside_castling_rights(chess.WHITE)),\n        'can_black_cstl_ks' : int(board.has_kingside_castling_rights(chess.BLACK)),\n        'can_black_cstl_qs' : int(board.has_queenside_castling_rights(chess.BLACK)),\n        # Total pieces for each color\n        'num_white_pieces': sum(len(board.pieces(piece_type, chess.WHITE)) for piece_type in chess.PIECE_TYPES),\n        'num_black_pieces': sum(len(board.pieces(piece_type, chess.BLACK)) for piece_type in chess.PIECE_TYPES),\n        # Board status. Each digit represents a status issue. 0 means no issues\n        'status' : board.status(),\n        # Number of BW turns\n        'round' : board.fullmove_number,\n        # Next turn. 1-white, 0-black\n        'is_white_to_move': int(board.turn),\n        \"row1\" : rows[0],\n        \"row2\" : rows[1],\n        \"row3\" : rows[2],\n        \"row4\" : rows[3],\n        \"row5\" : rows[4],\n        \"row6\" : rows[5],\n        \"row7\" : rows[6],\n        \"row8\" : rows[7],\n        \n    }\n    return features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:34.977297Z","iopub.execute_input":"2025-08-31T21:17:34.977694Z","iopub.status.idle":"2025-08-31T21:17:35.083533Z","shell.execute_reply.started":"2025-08-31T21:17:34.977669Z","shell.execute_reply":"2025-08-31T21:17:35.082394Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Parallelize FEN parsing\ndef parse_fen_parallel(fen_list, n_jobs=-1):\n    return Parallel(n_jobs=n_jobs)(delayed(parse_fen)(fen) for fen in fen_list)\n\n# Apply parallel parsing\n# Subset shuffle file\n# fen_list = df[0:1000000]['FEN'].tolist()\nfen_list = df[0:100000]['FEN']\nfen_features = parse_fen_parallel(fen_list)\nfeatures_df = pd.DataFrame(fen_features)\n\nfeatures_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:35.084848Z","iopub.execute_input":"2025-08-31T21:17:35.085263Z","iopub.status.idle":"2025-08-31T21:17:47.196801Z","shell.execute_reply.started":"2025-08-31T21:17:35.085225Z","shell.execute_reply":"2025-08-31T21:17:47.195607Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                 FEN  num_white_pawns  \\\n0  r1b4r/1p3kb1/p2pp1p1/3q3p/3N1Pp1/2P3R1/PP1Q1BP...                6   \n1    r1bqkb1r/pp3ppp/2np1n2/8/2BNP3/8/PP3PPP/RNBQK2R                6   \n2                         8/R7/5k2/2pqp3/6n1/8/8/1K6                0   \n3                      1r6/R3Pk2/6p1/2KB3p/5P2/8/8/8                2   \n4       2RB2bk/p2n3p/4Np2/8/2B3P1/1P3p1P/1P3P1K/2br4                5   \n\n   num_black_pawns  num_white_knights  num_black_knights  num_white_bishops  \\\n0                7                  1                  0                  1   \n1                6                  2                  2                  2   \n2                2                  0                  1                  0   \n3                2                  0                  0                  1   \n4                4                  1                  1                  2   \n\n   num_black_bishops  num_white_rooks  num_black_rooks  num_white_queens  ...  \\\n0                  2                2                2                 1  ...   \n1                  2                2                2                 1  ...   \n2                  0                1                0                 0  ...   \n3                  0                1                1                 0  ...   \n4                  2                1                1                 0  ...   \n\n   round  is_white_to_move      row1    row2     row3   row4    row5    row6  \\\n0     23                 1     r1b4r  1p3kb1  p2pp1p1   3q3p  3N1Pp1   2P3R1   \n1      4                 1  r1bqkb1r  pp3ppp   2np1n2      8   2BNP3       8   \n2     50                 0         8      R7      5k2  2pqp3     6n1       8   \n3     50                 0       1r6   R3Pk2      6p1  2KB3p     5P2       8   \n4     35                 1    2RB2bk   p2n3p     4Np2      8   2B3P1  1P3p1P   \n\n       row7     row8  \n0  PP1Q1BPP    4R1K1  \n1    PP3PPP  RNBQK2R  \n2         8      1K6  \n3         8        8  \n4    1P3P1K     2br4  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FEN</th>\n      <th>num_white_pawns</th>\n      <th>num_black_pawns</th>\n      <th>num_white_knights</th>\n      <th>num_black_knights</th>\n      <th>num_white_bishops</th>\n      <th>num_black_bishops</th>\n      <th>num_white_rooks</th>\n      <th>num_black_rooks</th>\n      <th>num_white_queens</th>\n      <th>...</th>\n      <th>round</th>\n      <th>is_white_to_move</th>\n      <th>row1</th>\n      <th>row2</th>\n      <th>row3</th>\n      <th>row4</th>\n      <th>row5</th>\n      <th>row6</th>\n      <th>row7</th>\n      <th>row8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>r1b4r/1p3kb1/p2pp1p1/3q3p/3N1Pp1/2P3R1/PP1Q1BP...</td>\n      <td>6</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>23</td>\n      <td>1</td>\n      <td>r1b4r</td>\n      <td>1p3kb1</td>\n      <td>p2pp1p1</td>\n      <td>3q3p</td>\n      <td>3N1Pp1</td>\n      <td>2P3R1</td>\n      <td>PP1Q1BPP</td>\n      <td>4R1K1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>r1bqkb1r/pp3ppp/2np1n2/8/2BNP3/8/PP3PPP/RNBQK2R</td>\n      <td>6</td>\n      <td>6</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>1</td>\n      <td>r1bqkb1r</td>\n      <td>pp3ppp</td>\n      <td>2np1n2</td>\n      <td>8</td>\n      <td>2BNP3</td>\n      <td>8</td>\n      <td>PP3PPP</td>\n      <td>RNBQK2R</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8/R7/5k2/2pqp3/6n1/8/8/1K6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>50</td>\n      <td>0</td>\n      <td>8</td>\n      <td>R7</td>\n      <td>5k2</td>\n      <td>2pqp3</td>\n      <td>6n1</td>\n      <td>8</td>\n      <td>8</td>\n      <td>1K6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1r6/R3Pk2/6p1/2KB3p/5P2/8/8/8</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>50</td>\n      <td>0</td>\n      <td>1r6</td>\n      <td>R3Pk2</td>\n      <td>6p1</td>\n      <td>2KB3p</td>\n      <td>5P2</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2RB2bk/p2n3p/4Np2/8/2B3P1/1P3p1P/1P3P1K/2br4</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>35</td>\n      <td>1</td>\n      <td>2RB2bk</td>\n      <td>p2n3p</td>\n      <td>4Np2</td>\n      <td>8</td>\n      <td>2B3P1</td>\n      <td>1P3p1P</td>\n      <td>1P3P1K</td>\n      <td>2br4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"#better to not select by index in case df changes.  Fix if time.\nX = features_df.iloc[:, 1:19]\n# y = df[0:100000]['WDL'].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:47.197939Z","iopub.execute_input":"2025-08-31T21:17:47.198301Z","iopub.status.idle":"2025-08-31T21:17:47.206730Z","shell.execute_reply.started":"2025-08-31T21:17:47.198270Z","shell.execute_reply":"2025-08-31T21:17:47.205201Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# map WDL values to categories\ny = pd.DataFrame(df[0:100000]['WDL'])\n\ntarget_encoding = {1:1, 0:0, .5:2}\ny['target'] = y['WDL'].map(target_encoding)\n\ny = pd.DataFrame(y['target'])\n\nprint(y.sample(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:17:47.208363Z","iopub.execute_input":"2025-08-31T21:17:47.208849Z","iopub.status.idle":"2025-08-31T21:17:47.286061Z","shell.execute_reply.started":"2025-08-31T21:17:47.208819Z","shell.execute_reply":"2025-08-31T21:17:47.284955Z"}},"outputs":[{"name":"stdout","text":"       target\n86195       1\n35867       1\n60519       0\n56484       1\n42832       1\n95300       2\n83968       1\n46933       2\n90014       1\n21715       0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size= 0.20, random_state=42)\n\nclf = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,\n                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n\nclf.fit(x_train, y_train)\n\ny_pred = clf.predict(x_test)\n\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:31:03.003987Z","iopub.execute_input":"2025-08-31T21:31:03.004325Z","iopub.status.idle":"2025-08-31T21:35:26.342311Z","shell.execute_reply.started":"2025-08-31T21:31:03.004299Z","shell.execute_reply":"2025-08-31T21:35:26.341130Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"name":"stdout","text":"Iteration 1, loss = 0.97166185\nIteration 2, loss = 0.92094040\nIteration 3, loss = 0.90642231\nIteration 4, loss = 0.89304108\nIteration 5, loss = 0.88897182\nIteration 6, loss = 0.88216278\nIteration 7, loss = 0.87691416\nIteration 8, loss = 0.87308160\nIteration 9, loss = 0.86786501\nIteration 10, loss = 0.86439778\nIteration 11, loss = 0.85985916\nIteration 12, loss = 0.85736701\nIteration 13, loss = 0.85670199\nIteration 14, loss = 0.85481775\nIteration 15, loss = 0.85127888\nIteration 16, loss = 0.85450441\nIteration 17, loss = 0.84971423\nIteration 18, loss = 0.85010298\nIteration 19, loss = 0.84587945\nIteration 20, loss = 0.84553303\nIteration 21, loss = 0.84411184\nIteration 22, loss = 0.84188226\nIteration 23, loss = 0.84065795\nIteration 24, loss = 0.84259747\nIteration 25, loss = 0.84160993\nIteration 26, loss = 0.83889681\nIteration 27, loss = 0.83948943\nIteration 28, loss = 0.83825262\nIteration 29, loss = 0.83615965\nIteration 30, loss = 0.83825291\nIteration 31, loss = 0.83768887\nIteration 32, loss = 0.83453661\nIteration 33, loss = 0.83416253\nIteration 34, loss = 0.83280898\nIteration 35, loss = 0.83215085\nIteration 36, loss = 0.83227134\nIteration 37, loss = 0.83361438\nIteration 38, loss = 0.83335218\nIteration 39, loss = 0.83119241\nIteration 40, loss = 0.82974415\nIteration 41, loss = 0.83059054\nIteration 42, loss = 0.82810321\nIteration 43, loss = 0.82903212\nIteration 44, loss = 0.82811643\nIteration 45, loss = 0.82696309\nIteration 46, loss = 0.82752094\nIteration 47, loss = 0.82817211\nIteration 48, loss = 0.82652065\nIteration 49, loss = 0.82716587\nIteration 50, loss = 0.82593760\nIteration 51, loss = 0.82482717\nIteration 52, loss = 0.82603370\nIteration 53, loss = 0.82606365\nIteration 54, loss = 0.82334188\nIteration 55, loss = 0.82553463\nIteration 56, loss = 0.82452689\nIteration 57, loss = 0.82399372\nIteration 58, loss = 0.82236199\nIteration 59, loss = 0.82488632\nIteration 60, loss = 0.82130697\nIteration 61, loss = 0.82272300\nIteration 62, loss = 0.82063021\nIteration 63, loss = 0.82141135\nIteration 64, loss = 0.82035570\nIteration 65, loss = 0.82045892\nIteration 66, loss = 0.82007022\nIteration 67, loss = 0.82090268\nIteration 68, loss = 0.82029590\nIteration 69, loss = 0.82008892\nIteration 70, loss = 0.82061952\nIteration 71, loss = 0.82000137\nIteration 72, loss = 0.81873261\nIteration 73, loss = 0.81922306\nIteration 74, loss = 0.81835349\nIteration 75, loss = 0.81954489\nIteration 76, loss = 0.81700711\nIteration 77, loss = 0.81839258\nIteration 78, loss = 0.81828791\nIteration 79, loss = 0.81816360\nIteration 80, loss = 0.81795444\nIteration 81, loss = 0.81756088\nIteration 82, loss = 0.81768794\nIteration 83, loss = 0.81711424\nIteration 84, loss = 0.81672132\nIteration 85, loss = 0.81561689\nIteration 86, loss = 0.81570492\nIteration 87, loss = 0.81588518\nIteration 88, loss = 0.81451751\nIteration 89, loss = 0.81683744\nIteration 90, loss = 0.81627819\nIteration 91, loss = 0.81587416\nIteration 92, loss = 0.81578908\nIteration 93, loss = 0.81575359\nIteration 94, loss = 0.81443700\nIteration 95, loss = 0.81615010\nIteration 96, loss = 0.81441838\nIteration 97, loss = 0.81542066\nIteration 98, loss = 0.81479565\nIteration 99, loss = 0.81546557\nIteration 100, loss = 0.81394942\nIteration 101, loss = 0.81440121\nIteration 102, loss = 0.81365261\nIteration 103, loss = 0.81344256\nIteration 104, loss = 0.81414539\nIteration 105, loss = 0.81498644\nIteration 106, loss = 0.81427394\nIteration 107, loss = 0.81321239\nIteration 108, loss = 0.81270077\nIteration 109, loss = 0.81328402\nIteration 110, loss = 0.81203967\nIteration 111, loss = 0.81337625\nIteration 112, loss = 0.81337050\nIteration 113, loss = 0.81181570\nIteration 114, loss = 0.81226688\nIteration 115, loss = 0.81166858\nIteration 116, loss = 0.81313016\nIteration 117, loss = 0.81286053\nIteration 118, loss = 0.81263409\nIteration 119, loss = 0.81128899\nIteration 120, loss = 0.81156962\nIteration 121, loss = 0.81204042\nIteration 122, loss = 0.81055641\nIteration 123, loss = 0.81128387\nIteration 124, loss = 0.81035987\nIteration 125, loss = 0.81194628\nIteration 126, loss = 0.81037230\nIteration 127, loss = 0.81050436\nIteration 128, loss = 0.81179406\nIteration 129, loss = 0.81102858\nIteration 130, loss = 0.81046530\nIteration 131, loss = 0.81019048\nIteration 132, loss = 0.81148182\nIteration 133, loss = 0.81036853\nIteration 134, loss = 0.81057258\nIteration 135, loss = 0.80971410\nIteration 136, loss = 0.80967208\nIteration 137, loss = 0.80966916\nIteration 138, loss = 0.80932784\nIteration 139, loss = 0.80907604\nIteration 140, loss = 0.81063741\nIteration 141, loss = 0.81020152\nIteration 142, loss = 0.81025412\nIteration 143, loss = 0.80911542\nIteration 144, loss = 0.80979249\nIteration 145, loss = 0.80930089\nIteration 146, loss = 0.81001240\nIteration 147, loss = 0.80976903\nIteration 148, loss = 0.80879894\nIteration 149, loss = 0.80980547\nIteration 150, loss = 0.80921612\nIteration 151, loss = 0.80896570\nIteration 152, loss = 0.80811628\nIteration 153, loss = 0.80859484\nIteration 154, loss = 0.80855012\nIteration 155, loss = 0.80727214\nIteration 156, loss = 0.80918629\nIteration 157, loss = 0.80761550\nIteration 158, loss = 0.80875136\nIteration 159, loss = 0.80792796\nIteration 160, loss = 0.80727193\nIteration 161, loss = 0.80715311\nIteration 162, loss = 0.80748103\nIteration 163, loss = 0.80733349\nIteration 164, loss = 0.80683021\nIteration 165, loss = 0.80720121\nIteration 166, loss = 0.80741241\nIteration 167, loss = 0.80690939\nIteration 168, loss = 0.80661149\nIteration 169, loss = 0.80628374\nIteration 170, loss = 0.80675144\nIteration 171, loss = 0.80645144\nIteration 172, loss = 0.80617386\nIteration 173, loss = 0.80598240\nIteration 174, loss = 0.80738446\nIteration 175, loss = 0.80690239\nIteration 176, loss = 0.80675584\nIteration 177, loss = 0.80629700\nIteration 178, loss = 0.80580877\nIteration 179, loss = 0.80556611\nIteration 180, loss = 0.80623763\nIteration 181, loss = 0.80596047\nIteration 182, loss = 0.80644835\nIteration 183, loss = 0.80521448\nIteration 184, loss = 0.80503098\nIteration 185, loss = 0.80552796\nIteration 186, loss = 0.80509176\nIteration 187, loss = 0.80553040\nIteration 188, loss = 0.80536791\nIteration 189, loss = 0.80467865\nIteration 190, loss = 0.80541765\nIteration 191, loss = 0.80457079\nIteration 192, loss = 0.80480147\nIteration 193, loss = 0.80535890\nIteration 194, loss = 0.80465103\nIteration 195, loss = 0.80554094\nIteration 196, loss = 0.80485728\nIteration 197, loss = 0.80378480\nIteration 198, loss = 0.80406909\nIteration 199, loss = 0.80442883\nIteration 200, loss = 0.80421373\nIteration 201, loss = 0.80436554\nIteration 202, loss = 0.80460430\nIteration 203, loss = 0.80433847\nIteration 204, loss = 0.80452167\nIteration 205, loss = 0.80493621\nIteration 206, loss = 0.80398897\nIteration 207, loss = 0.80329196\nIteration 208, loss = 0.80409379\nIteration 209, loss = 0.80345232\nIteration 210, loss = 0.80402389\nIteration 211, loss = 0.80348521\nIteration 212, loss = 0.80287269\nIteration 213, loss = 0.80298842\nIteration 214, loss = 0.80337157\nIteration 215, loss = 0.80343730\nIteration 216, loss = 0.80396534\nIteration 217, loss = 0.80253125\nIteration 218, loss = 0.80275334\nIteration 219, loss = 0.80326725\nIteration 220, loss = 0.80197895\nIteration 221, loss = 0.80282662\nIteration 222, loss = 0.80230176\nIteration 223, loss = 0.80242473\nIteration 224, loss = 0.80320160\nIteration 225, loss = 0.80339848\nIteration 226, loss = 0.80214067\nIteration 227, loss = 0.80296641\nIteration 228, loss = 0.80220499\nIteration 229, loss = 0.80164190\nIteration 230, loss = 0.80182405\nIteration 231, loss = 0.80238414\nIteration 232, loss = 0.80182757\nIteration 233, loss = 0.80109227\nIteration 234, loss = 0.80197147\nIteration 235, loss = 0.80220300\nIteration 236, loss = 0.80210550\nIteration 237, loss = 0.80231716\nIteration 238, loss = 0.80256629\nIteration 239, loss = 0.80152485\nIteration 240, loss = 0.80230426\nIteration 241, loss = 0.80155226\nIteration 242, loss = 0.80204082\nIteration 243, loss = 0.80201341\nIteration 244, loss = 0.80189915\nTraining loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\nConfusion Matrix:\n [[1110 1487  878]\n [ 185 6155 1905]\n [ 416 2914 4950]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.65      0.32      0.43      3475\n           1       0.58      0.75      0.65      8245\n           2       0.64      0.60      0.62      8280\n\n    accuracy                           0.61     20000\n   macro avg       0.62      0.55      0.57     20000\nweighted avg       0.62      0.61      0.60     20000\n\n","output_type":"stream"}],"execution_count":12}]}